{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOoLrQG2/Da5DFPf48rvmsw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vadaliah/CS5260/blob/master/VWAP%20ML%20Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E7qUWeleJWjg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Forex VWAP(Volume Weighted Average Price) ML Solution using scikit-learn**\n",
        "\n",
        "This notebook demonstrates Machine Learning solution to predict VWAP direction for given currency pair based on historical volume dataset\n",
        "\n",
        "**Problem Formulation**\n",
        "\n",
        "In this example, we will use Historical Currencypair price volume dataset provided from FOREX Tester APP, available here: https://forextester.com/data/datasources.\n",
        "\n",
        "The dataset contains Hourly pricing data of 6 currency pair (EURUSD, GBPUSD, AUDUSD, NZSUSD, USDJPY and USDCHF) for April 2018."
      ],
      "metadata": {
        "id": "lfddLp7fJX5T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "EDA Validation:\n",
        "1. Ensure data is complete, verify presence of  data for all 6 currency pair is present in the volume dataset\n",
        "2.  Verify count of data by currencypair, businessdate combination.\n",
        "  Any currencypair with insufficient data will skew VWAP results and result in inaccurate model outcome\n",
        "3. Verify Trading dataset is complete, contains currency pair and business dates in scope\n",
        "4. Esnure Join between CurrencyPair volume and Trading dataset is successful and there is matching attributes in both the datasets\n"
      ],
      "metadata": {
        "id": "mYxqwQ_nKbY3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  import pandas as pd\n",
        "  import numpy as np\n",
        "  import seaborn as sns\n",
        "  import matplotlib.pyplot as plt\n",
        "  from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "  from sklearn.linear_model import LogisticRegression\n",
        "  from sklearn.ensemble import RandomForestClassifier\n",
        "  from sklearn.pipeline import Pipeline\n",
        "  from sklearn.compose import ColumnTransformer, make_column_selector\n",
        "  from sklearn.impute import SimpleImputer\n",
        "  from sklearn.preprocessing import OneHotEncoder, LabelBinarizer, StandardScaler\n",
        "  from sklearn import config_context\n",
        "  from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "  from google.colab import files\n",
        "\n",
        "  fx_volume_file = 'https://raw.githubusercontent.com/vadaliah/CS5260/master/currencypair_volume_datset.csv'\n",
        "  fx_volume_df = pd.read_csv(fx_volume_file)\n",
        "  fx_volume_df.sample(5)\n",
        "  print(fx_volume_df.shape)\n",
        "  print(fx_volume_df.size)\n",
        "  fx_volume_df.head().values\n",
        "\n",
        "  fx_trade_file = 'https://raw.githubusercontent.com/vadaliah/CS5260/master/trade_dataset.csv'\n",
        "  fx_trade_df = pd.read_csv(fx_trade_file)\n",
        "  print(fx_trade_df.shape)\n",
        "  print(fx_trade_df.size)\n",
        "  fx_trade_df.head().values"
      ],
      "metadata": {
        "id": "sKCzYP1cPDzg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc1f4310-6cd8-4c5e-eece-2e6d7c7395c3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3013, 8)\n",
            "24104\n",
            "(14327, 1)\n",
            "14327\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['USDJPY\\t20180401\\t21:00\\t2101\\t106.167'],\n",
              "       ['USDJPY\\t20180401\\t21:00\\t2102\\t106.189'],\n",
              "       ['USDJPY\\t20180401\\t21:00\\t2105\\t106.221'],\n",
              "       ['USDJPY\\t20180401\\t21:00\\t2106\\t106.219'],\n",
              "       ['USDJPY\\t20180401\\t21:00\\t2107\\t106.222']], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fx_volume_df.info()\n",
        "fx_volume_df.columns\n",
        "fx_volume_df['Ticker'].value_counts()\n",
        "fx_volume_df[['Ticker','BusinessDate','TimeBucket']].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYz2kBSOMD3p",
        "outputId": "0df7587a-5607-40e4-fb5e-982b16cf8239"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3013 entries, 0 to 3012\n",
            "Data columns (total 8 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   Ticker        3013 non-null   object \n",
            " 1   BusinessDate  3013 non-null   int64  \n",
            " 2   TimeBucket    3013 non-null   object \n",
            " 3   Open          3013 non-null   float64\n",
            " 4   High          3013 non-null   float64\n",
            " 5   Low           3013 non-null   float64\n",
            " 6   Close         3013 non-null   float64\n",
            " 7   Volume        3013 non-null   int64  \n",
            "dtypes: float64(4), int64(2), object(2)\n",
            "memory usage: 188.4+ KB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Ticker  BusinessDate  TimeBucket\n",
              "GBPUSD  20180406      20:00         2\n",
              "NZDUSD  20180410      20:00         2\n",
              "USDCHF  20180406      10:00         2\n",
              "NZDUSD  20180410      10:00         2\n",
              "        20180427      10:00         2\n",
              "                                   ..\n",
              "EURUSD  20180430      18:00         1\n",
              "                      19:00         1\n",
              "                      1:00          1\n",
              "                      20:00         1\n",
              "USDJPY  20180430      9:00          1\n",
              "Length: 2831, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fx_trade_df.info()\n",
        "fx_trade_df.columns\n",
        "fx_trade_df.describe()\n",
        "fx_trade_df['Ticker'].value_counts()\n",
        "fx_trade_df[['Ticker','BusinessDate']].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZ8NrL5aOOrD",
        "outputId": "20be2050-b664-41be-b5da-a1bb55e81a13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 14327 entries, 0 to 14326\n",
            "Data columns (total 5 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   Ticker        14327 non-null  object \n",
            " 1   BusinessDate  14327 non-null  int64  \n",
            " 2   Time_Bucket   14327 non-null  object \n",
            " 3   TradeTime     14327 non-null  int64  \n",
            " 4   TradePrice    14327 non-null  float64\n",
            "dtypes: float64(1), int64(2), object(2)\n",
            "memory usage: 559.8+ KB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Ticker  BusinessDate\n",
              "EURUSD  20180430        1440\n",
              "GBPUSD  20180430        1439\n",
              "AUDUSD  20180430        1438\n",
              "NZDUSD  20180430        1436\n",
              "USDJPY  20180430        1432\n",
              "AUDUSD  20180420        1260\n",
              "EURUSD  20180420        1260\n",
              "GBPUSD  20180420        1260\n",
              "NZDUSD  20180420        1260\n",
              "USDJPY  20180420        1258\n",
              "EURUSD  20180401         178\n",
              "GBPUSD  20180401         177\n",
              "AUDUSD  20180401         176\n",
              "NZDUSD  20180401         157\n",
              "USDJPY  20180401         156\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ED Criteria validated:\n",
        "1. Validate presence of FX_Volume_df  data for CurrencyPair and BusinessDate key parameters\n",
        "2. Validated presence of FX_Trade_df  data for CurrencyPair and BusinessDate key parameters\n",
        "3. Validate join condition between FX_Volume_df and FX_Trade_DF  using Time_Bucket(Hour) value. Currently giving error due to duplicate key that requires data to be reviewed"
      ],
      "metadata": {
        "id": "BibV92zkXhbT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Engineering tasks: \n",
        "1. Transform tasks to compute avg_price column as avg of Open, Close, High and Low prices\n",
        "2. Transform task to compute PV column as avg_price*volume\n",
        "3. Impute sum of PV by ['Ticker','BusinessDate'] to populate cumulative_pv\n",
        "4. Transform task to compute VWAP as cumulative_pv/volume\n",
        "5. Merge FX_Volume_df data and FX_Trade_df dataset on 'Ticker','BusinessDate','Time_Bucket' Key to generate ML Model View"
      ],
      "metadata": {
        "id": "bws2Md58YtBM"
      }
    }
  ]
}