{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO2nE56iirp3L6RfauNuDOk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vadaliah/CS5260/blob/master/HW3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNWYeqdKnhVO",
        "outputId": "e9b8b53c-b145-4d31-9b18-541c4d2c6974"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd gdrive/MyDrive/Colab\\ Notebooks/HW3_Full"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDJGDTrhn-yQ",
        "outputId": "4ef22170-b3db-4373-b6c8-6c758921076e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/Colab Notebooks/HW3_Full\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install torch_utils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfLDM6X4p8MA",
        "outputId": "db5968f7-eb75-4d03-ca07-f449161233ea"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch_utils\n",
            "  Downloading torch-utils-0.1.2.tar.gz (4.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from torch_utils) (2.0.0+cu118)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch->torch_utils) (2.0.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch->torch_utils) (4.5.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch->torch_utils) (3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch->torch_utils) (3.1.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch->torch_utils) (1.11.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch->torch_utils) (3.10.7)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch->torch_utils) (16.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch->torch_utils) (3.25.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch->torch_utils) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch->torch_utils) (1.3.0)\n",
            "Building wheels for collected packages: torch_utils\n",
            "  Building wheel for torch_utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch_utils: filename=torch_utils-0.1.2-py3-none-any.whl size=6202 sha256=b7823c8d3a541ad42da9a53cf7e91630bd4760d1f77ce5b274767e647a9f8aec\n",
            "  Stored in directory: /root/.cache/pip/wheels/b9/ae/b4/56ed29da706ea5e0f79157a9b158aad24bfabd045ef42eed75\n",
            "Successfully built torch_utils\n",
            "Installing collected packages: torch_utils\n",
            "Successfully installed torch_utils-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "\n",
        "# import modules\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import cuda\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader, sampler\n",
        "import torch.nn.functional as F\n",
        "from torch_utils import AverageMeter\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from numpy import inf\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "from glob import glob\n",
        "from torchvision import transforms\n",
        "from torchvision import datasets\n",
        "from torchvision import models\n",
        "from torch import optim, cuda, Tensor\n",
        "import tqdm\n",
        "\n",
        "# Data science tools\n",
        "import numpy as np\n",
        "\n",
        "import os\n",
        "\n",
        "# Image manipulations\n",
        "from PIL import Image\n",
        "from timeit import default_timer as timer\n",
        "\n",
        "# Visualizations\n",
        "import matplotlib.pyplot as plt\n",
        "#plt.rcParams['font.size'] = 14\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore', category=FutureWarning)"
      ],
      "metadata": {
        "id": "Eqi18g4gqOCp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define model\n",
        "class bmodel(nn.Module):\n",
        "    def __init__(self, input_d, hidden_d, output_d):\n",
        "        super().__init__()\n",
        "        # Define all the layers that you need in your network\n",
        "        # You can use nn.Linear() to define the linear layer\n",
        "        # You can use nn.Dropout() to define the dropout layer\n",
        "        # You can use F.relu() to define your ReLu layer\n",
        "       # Weights and biases can be create using nn.Parameter, which has requires_grad\n",
        "        \n",
        "        self.w00 = nn.Parameter(torch.randn(1), requires_grad=True)\n",
        "        self.b00 = nn.Parameter(torch.randn(1), requires_grad=True)\n",
        "        # num of ws = num of inputs\n",
        "        # num of bs = 1 for each neuron\n",
        "        self.w01 = nn.Parameter(torch.randn(1), requires_grad=True)\n",
        "        self.b01 = nn.Parameter(torch.randn(1), requires_grad=True)\n",
        "                \n",
        "        self.w10 = nn.Parameter(torch.randn(1), requires_grad=True)\n",
        "        self.w11 = nn.Parameter(torch.randn(1), requires_grad=True)\n",
        "        self.b10 = nn.Parameter(torch.randn(1), requires_grad=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Design your network structure here\n",
        "          h00 = x * self.w00 + self.b00\n",
        "          h00_out = F.relu(h00)\n",
        "   \n",
        "          h01 = x * self.w01 + self.b01\n",
        "          h01_out = F.relu(h01)\n",
        "          h1 = h00_out * self.w10 + h01_out * self.w11 + self.b10\n",
        "   \n",
        "   # Since the model is binary classification, we apply sigmoid\n",
        "          output = torch.sigmoid(h1)\n",
        "   \n",
        "          return output\n"
      ],
      "metadata": {
        "id": "lp5BBLAOq_TP"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a small net and some toy data to check your implementations.\n",
        "# Note that we set the random seed for repeatable experiments.\n",
        "\n",
        "input_size = 4\n",
        "hidden_size = 10\n",
        "num_classes = 3\n",
        "num_inputs = 5\n",
        "\n",
        "def init_toy_model():\n",
        "    np.random.seed(0)\n",
        "    return bmodel(input_size, hidden_size, num_classes)\n",
        "\n",
        "def init_toy_data():\n",
        "    np.random.seed(1)\n",
        "    X = 10 * np.random.randn(num_inputs, input_size)\n",
        "    y = np.array([0, 1, 2, 2, 1])\n",
        "    return X, y\n",
        "\n",
        "toy_model = init_toy_model()\n",
        "train_X, train_Y = init_toy_data()\n",
        "validation_X, validation_Y = init_toy_data()"
      ],
      "metadata": {
        "id": "4oGc0V_G6x3E"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check whether there is a gpu for cuda\n",
        "import torch\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "print(f'Train on gpu: {train_on_gpu}')\n",
        "\n",
        "# Number of gpus\n",
        "if train_on_gpu:\n",
        "    gpu_count = torch.cuda.device_count()\n",
        "    print(f'{gpu_count} gpus detected.')\n",
        "    if gpu_count > 1:\n",
        "        multi_gpu = True\n",
        "    else:\n",
        "        multi_gpu = False\n",
        "else:\n",
        "    multi_gpu = False\n",
        "print(train_on_gpu,multi_gpu)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1gmvpdB7dod",
        "outputId": "e0f283f4-a45e-49d6-d291-c9ebd3121a87"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train on gpu: True\n",
            "1 gpus detected.\n",
            "True False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# torch.linspace() creates the sequence of numbers between start and end, inclusively\n",
        "toy_inputs = torch.linspace(start=100000, end=500000, steps=10) # same # of inputs\n",
        "# [100000, 150000, ... 500000]\n",
        "toy_labels = torch.tensor([0., 0., 0., 1., 1., 0., 1., 1., 1., 1.]) # same # of outputs\n",
        "\n",
        "\n",
        "################################################################################################################ \n",
        "# TODO: Uncomment code below to see the effect of feature scaling!\n",
        "# X_mean = torch.mean(toy_inputs, dim=0) # Compute the mean of each feature across all samples\n",
        "# X_std = torch.std(toy_inputs, dim=0) # Compute the standard deviation of each feature across all samples\n",
        "\n",
        "# # Normalize the inputs using the mean and standard deviation\n",
        "# toy_inputs = (toy_inputs - X_mean) / X_std\n",
        "################################################################################################################ \n",
        "\n",
        "\n",
        "# create the ToyModel\n",
        "model = ToyModel()\n",
        "\n",
        "optimizer = SGD(model.parameters(), lr=0.05)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "previous_total_loss = 0\n",
        "for epoch in range(100):\n",
        "\n",
        "    total_loss = 0\n",
        "    \n",
        "    # going through my inputs\n",
        "    for iteration in range(len(toy_inputs)):\n",
        "        \n",
        "        input_i = toy_inputs[iteration]  # x\n",
        "        label_i = toy_inputs[iteration]  # y\n",
        "        \n",
        "        # 1 - forward pass\n",
        "        output_i = model(input_i) ## calculate the neural network output for one input\n",
        "        \n",
        "        # 2 - compute loss\n",
        "        loss = criterion(output_i.squeeze(), label_i)\n",
        "\n",
        "        # 3 - backprop\n",
        "        loss.backward() # calculates the gradient for a single value and adds it to the previous one\n",
        "        \n",
        "        total_loss += float(loss.item()) # add the total loss for this epoch.\n",
        "        \n",
        "    # early stopping\n",
        "    if (total_loss < 0.5):\n",
        "        print(\"Epoch #\" + str(epoch))\n",
        "        break\n",
        "      \n",
        "    optimizer.step() # update the parameters\n",
        "    optimizer.zero_grad() # zero out the previous gradient\n",
        "    \n",
        "\n",
        "    print(\"Total loss: \" + str(total_loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "pPRUG4WeMwYG",
        "outputId": "be878374-3233-4460-ce88-64b20d51c4cc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-0daaf8fb1ecc>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# create the ToyModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mToyModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ToyModel' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Datasets organization\n",
        "batch_size = 1\n",
        "\n",
        "# Transfer the data from numpy to tensor\n",
        "data = {\n",
        "    'train':\n",
        "    TensorDataset(torch.from_numpy(train_X), torch.from_numpy(train_Y).float()),\n",
        "    'valid':\n",
        "    # please define your validation dataset\n",
        "    ######################\n",
        "    ### YOUR CODE HERE ###\n",
        "    ######################\n",
        "    \n",
        "    #####################\n",
        "    ### YOUR CODE END ###\n",
        "    #####################\n",
        "\n",
        "}\n"
      ],
      "metadata": {
        "id": "28QP34jw-F8N"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}